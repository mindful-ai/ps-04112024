{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Sentiment Analysis of Movie Reviews (NLP Example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Data Collection: You need a dataset of movie reviews. For this example, we will use NLTK's built-in dataset of movie reviews, which is pre-labeled as positive or negative.\n",
    "\n",
    "Preprocessing: Tokenize and preprocess the text data.\n",
    "\n",
    "Modeling: Train a simple sentiment classifier (using Naive Bayes) to classify movie reviews as positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\mindf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mindf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mindf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('movie_reviews')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "fileids = movie_reviews.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare labeled data: (word features, label)\n",
    "documents = [(list(movie_reviews.words(fileid)), fileid.split('/')[0]) for fileid in fileids]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the documents for random training/test split\n",
    "random.shuffle(documents)\n",
    "\n",
    "# Prepare stopwords to remove unnecessary words\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract features from text\n",
    "def extract_features(words):\n",
    "    words = [word.lower() for word in words if word.isalpha()]  # Remove non-alphabetic tokens and convert to lowercase\n",
    "    words = [word for word in words if word not in stop_words]  # Remove stop words\n",
    "    return {word: True for word in words}\n",
    "\n",
    "# Create feature sets for training\n",
    "featuresets = [(extract_features(doc), label) for doc, label in documents]\n",
    "\n",
    "# Split into training and test sets (80% training, 20% testing)\n",
    "train_set, test_set = featuresets[:int(len(featuresets) * 0.8)], featuresets[int(len(featuresets) * 0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Accuracy: 71.25%\n"
     ]
    }
   ],
   "source": [
    "# Train the Naive Bayes classifier\n",
    "classifier = NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "# Test the classifier\n",
    "accuracy = nltk.classify.accuracy(classifier, test_set)\n",
    "print(f\"Classifier Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1 sentiment: pos\n",
      "Review 2 sentiment: neg\n"
     ]
    }
   ],
   "source": [
    "def classify_review(review):\n",
    "    # Tokenize and extract features from the review text\n",
    "    features = extract_features(word_tokenize(review))\n",
    "    return classifier.classify(features)\n",
    "\n",
    "# Example movie reviews\n",
    "review1 = \"The movie was fantastic! I absolutely loved the storyline and the acting was superb.\"\n",
    "review2 = \"It was a terrible movie. The plot was boring and the characters were flat.\"\n",
    "\n",
    "# Classify the reviews\n",
    "print(f\"Review 1 sentiment: {classify_review(review1)}\")  # Positive\n",
    "print(f\"Review 2 sentiment: {classify_review(review2)}\")  # Negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing: We load the movie_reviews corpus, which consists of 1,000 labeled reviews (500 positive and 500 negative). We then shuffle the reviews to randomize the order and split them into training and test sets.\n",
    "\n",
    "Feature Extraction: For each review, we extract features based on the words in the review, ignoring stopwords (common words like \"and\", \"the\", etc.) and non-alphabetic characters. Each word becomes a feature, and we set its value to True to indicate its presence.\n",
    "\n",
    "Training: We use Naive Bayes classifier to train the model using the training dataset. NLTK provides an easy-to-use implementation of Naive Bayes for classification tasks.\n",
    "\n",
    "Testing: We test the classifier using the test set and print the accuracy. The model is then used to predict the sentiment of new movie reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
